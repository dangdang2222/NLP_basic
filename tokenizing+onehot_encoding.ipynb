{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQTtiN6F3KDb",
        "outputId": "1dc60281-26a1-4bf1-9c9f-31fdcd0dbfaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"all\", quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wLAHIFs_zPZ",
        "outputId": "9a9562f6-7ec1-4f9a-f514-b58f42fc0fed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Friends, Romans, Countrymen, lend me your ears;.\"\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnB9YoVX_5vT",
        "outputId": "0f42d093-6ea4-408c-b8c0-f22321161215"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Friends', ',', 'Romans', ',', 'Countrymen', ',', 'lend', 'me', 'your', 'ears', ';', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"Natural language processing (NLP) is a subfield of \\\n",
        "linguistics, computer science, and artificial intelligence \\\n",
        "concerned with the interactions between computers and human language, \\\n",
        "in particular how to program computers to process and analyze large \\\n",
        "amounts of natural language data. The goal is a computer capable of \\\n",
        "understanding the contents of documents, including the contextual \\\n",
        "nuances of the language within them. The technology can then accurately \\\n",
        "extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\n",
        "\n",
        "print(sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9R1kqc8AEDL",
        "outputId": "4510ff52-0395-456d-97ce-ccbf27479603"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.', 'The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them.', 'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot Encoding"
      ],
      "metadata": {
        "id": "3Nwvex7jALlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "6V-S5Y4YAJrA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "print(set(data))\n",
        "values = array(data)\n",
        "print(values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-rQBSyAVn3",
        "outputId": "179bb5f2-fc5c-4ab9-ffee-368ee7484760"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cold', 'warm', 'hot'}\n",
            "['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ko7N457Acvd",
        "outputId": "dd0f8344-4202-4c26-b6a3-e70668781205"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 0 1 1 2 0 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integer_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rblMrM3Ay8A",
        "outputId": "bf27d108-0541-416b-adda-41e7864a535c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
        "print(integer_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reszh0qKAxDM",
        "outputId": "12be34e1-75b8-4951-f898-06c90d38b869"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [2]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)"
      ],
      "metadata": {
        "id": "w-CoGHRqBJy-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(onehot_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI_ltL01BScj",
        "outputId": "12739c53-aea5-4920-e4e4-1aa192ebf160"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "argmax(onehot_encoded[0,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52iv-Yr7BZ1q",
        "outputId": "dbeff348-fed7-4191-a6c1-e7d9bfb45f87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[:,:])])\n",
        "print(inverted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMJiQ4F5BTzH",
        "outputId": "a276c28f-6679-46ab-ef4b-189f5d8b5018"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cold']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eh_in2czZoAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(onehot_encoded)):\n",
        "  inverted = label_encoder.inverse_transform([argmax(onehot_encoded[x,:])])\n",
        "  print(inverted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ93w61rZGfU",
        "outputId": "c3ed0730-8be5-4d07-c588-cbdaa3cf1f65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cold']\n",
            "['cold']\n",
            "['warm']\n",
            "['cold']\n",
            "['hot']\n",
            "['hot']\n",
            "['warm']\n",
            "['cold']\n",
            "['warm']\n",
            "['hot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTq8TGaGZYrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}